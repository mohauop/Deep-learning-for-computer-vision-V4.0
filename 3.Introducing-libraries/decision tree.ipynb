{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b26f156a",
   "metadata": {
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1709132205002,
     "user": {
      "displayName": "Cylia Khelifi",
      "userId": "15337881315503988180"
     },
     "user_tz": -60
    },
    "id": "b26f156a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf0d2976",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "executionInfo": {
     "elapsed": 308,
     "status": "error",
     "timestamp": 1709132211037,
     "user": {
      "displayName": "Cylia Khelifi",
      "userId": "15337881315503988180"
     },
     "user_tz": -60
    },
    "id": "cf0d2976",
    "outputId": "7a606cb9-65a5-4d93-83ea-cfc8f47a6c51"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width    type\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa\n",
       "2           4.7          3.2           1.3          0.2  Setosa\n",
       "3           4.6          3.1           1.5          0.2  Setosa\n",
       "4           5.0          3.6           1.4          0.2  Setosa"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'type']\n",
    "data = pd.read_csv(\"iris.csv\", skiprows=1, header=None, names=col_names)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5825107c",
   "metadata": {
    "id": "5825107c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This defines a Node class to represent nodes in the decision tree.\\n    It has attributes for decision nodes (feature_index, threshold, left, right, info_gain) and leaf nodes (value). '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' This defines a Node class to represent nodes in the decision tree.\n",
    "    It has attributes for decision nodes (feature_index, threshold, left, right, info_gain) and leaf nodes (value). '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c79a7295",
   "metadata": {
    "id": "c79a7295"
   },
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
    "        ''' constructor '''\n",
    "\n",
    "        # for decision node\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.info_gain = info_gain\n",
    "\n",
    "        # for leaf node\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cc2418f",
   "metadata": {
    "id": "7cc2418f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Defines the DecisionTreeClassifier class with constructor parameters for minimum\\n    samples to split (min_samples_split) and maximum depth (max_depth).\\n      It initializes the root as None. '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Defines the DecisionTreeClassifier class with constructor parameters for minimum\n",
    "    samples to split (min_samples_split) and maximum depth (max_depth).\n",
    "      It initializes the root as None. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a6aeccb",
   "metadata": {
    "id": "5a6aeccb"
   },
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier():\n",
    "    def __init__(self, min_samples_split=2, max_depth=2):\n",
    "        ''' constructor '''\n",
    "\n",
    "        # initialize the root of the tree\n",
    "        self.root = None\n",
    "\n",
    "        # stopping conditions\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "\n",
    "        '''  This method is a recursive function to build the decision tree. It takes a dataset and the current depth as input.\n",
    "        If stopping conditions (minimum samples and maximum depth) are met, it finds the best split using the get_best_split method.\n",
    "        If the information gain is positive, it recurs on the left and right subtrees and returns a decision node.\n",
    "        If stopping conditions are not met, it computes the leaf node. '''\n",
    "\n",
    "\n",
    "\n",
    "    def build_tree(self, dataset, curr_depth=0):\n",
    "        ''' recursive function to build the tree '''\n",
    "\n",
    "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
    "        num_samples, num_features = np.shape(X)\n",
    "\n",
    "        # split until stopping conditions are met\n",
    "        if num_samples>=self.min_samples_split and curr_depth<=self.max_depth:\n",
    "            # find the best split\n",
    "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
    "            # check if information gain is positive\n",
    "            if best_split[\"info_gain\"]>0:\n",
    "                # recur left\n",
    "                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth+1)\n",
    "                # recur right\n",
    "                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth+1)\n",
    "                # return decision node\n",
    "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"],\n",
    "                            left_subtree, right_subtree, best_split[\"info_gain\"])\n",
    "\n",
    "        # compute leaf node\n",
    "        leaf_value = self.calculate_leaf_value(Y)\n",
    "        # return leaf node\n",
    "        return Node(value=leaf_value)\n",
    "\n",
    "\n",
    "    '''  In summary, the get_best_split function iterates over each feature and its unique values, considering each value as a potential threshold.\n",
    "        For each split, it calculates the information gain using the Gini index criterion and updates the best_split dictionary if the current split\n",
    "        yields a higher information gain than the previous best split. The function returns the details of the best split found in the dataset. '''\n",
    "\n",
    "\n",
    "    def get_best_split(self, dataset, num_samples, num_features):\n",
    "        ''' function to find the best split '''\n",
    "\n",
    "        # dictionary to store the best split\n",
    "        best_split = {}\n",
    "        max_info_gain = -float(\"inf\")\n",
    "\n",
    "        # loop over all the features\n",
    "        for feature_index in range(num_features):\n",
    "            feature_values = dataset[:, feature_index]\n",
    "            possible_thresholds = np.unique(feature_values)\n",
    "            # loop over all the feature values present in the data\n",
    "            for threshold in possible_thresholds:\n",
    "                # get current split\n",
    "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
    "                # check if childs are not null\n",
    "                if len(dataset_left)>0 and len(dataset_right)>0:\n",
    "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
    "                    # compute information gain\n",
    "                    curr_info_gain = self.information_gain(y, left_y, right_y, \"gini\")\n",
    "                    # update the best split if needed\n",
    "                    if curr_info_gain>max_info_gain:\n",
    "                        best_split[\"feature_index\"] = feature_index\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"dataset_left\"] = dataset_left\n",
    "                        best_split[\"dataset_right\"] = dataset_right\n",
    "                        best_split[\"info_gain\"] = curr_info_gain\n",
    "                        max_info_gain = curr_info_gain\n",
    "\n",
    "        # return best split\n",
    "        return best_split\n",
    "\n",
    "    def split(self, dataset, feature_index, threshold):\n",
    "        ''' function to split the data '''\n",
    "\n",
    "        dataset_left = np.array([row for row in dataset if row[feature_index]<=threshold])\n",
    "        dataset_right = np.array([row for row in dataset if row[feature_index]>threshold])\n",
    "        return dataset_left, dataset_right\n",
    "\n",
    "    def information_gain(self, parent, l_child, r_child, mode=\"entropy\"):\n",
    "        ''' function to compute information gain '''\n",
    "\n",
    "        weight_l = len(l_child) / len(parent)\n",
    "        weight_r = len(r_child) / len(parent)\n",
    "        if mode==\"gini\":\n",
    "            gain = self.gini_index(parent) - (weight_l*self.gini_index(l_child) + weight_r*self.gini_index(r_child))\n",
    "        else:\n",
    "            gain = self.entropy(parent) - (weight_l*self.entropy(l_child) + weight_r*self.entropy(r_child))\n",
    "        return gain\n",
    "\n",
    "    def entropy(self, y):\n",
    "        ''' function to compute entropy '''\n",
    "\n",
    "        class_labels = np.unique(y)\n",
    "        #find the classes by keeping only unique values\n",
    "\n",
    "        entropy = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            entropy += -p_cls * np.log2(p_cls)\n",
    "        return entropy\n",
    "\n",
    "    def gini_index(self, y):\n",
    "        ''' function to compute gini index '''\n",
    "\n",
    "        class_labels = np.unique(y)\n",
    "        gini = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            gini += p_cls**2\n",
    "        return 1 - gini\n",
    "\n",
    "    def calculate_leaf_value(self, Y):\n",
    "        ''' function to compute leaf node '''\n",
    "\n",
    "        Y = list(Y)\n",
    "        return max(Y, key=Y.count)\n",
    "\n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "        ''' function to print the tree '''\n",
    "\n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "\n",
    "        else:\n",
    "            print(\"X_\"+str(tree.feature_index), \"<=\", tree.threshold, \"?\", tree.info_gain)\n",
    "            print(\"%sleft:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.left, indent + indent)\n",
    "            print(\"%sright:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.right, indent + indent)\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        ''' function to train the tree '''\n",
    "\n",
    "        dataset = np.concatenate((X, Y), axis=1)\n",
    "        self.root = self.build_tree(dataset)\n",
    "\n",
    "    def predict(self, X):\n",
    "        ''' function to predict new dataset '''\n",
    "\n",
    "        preditions = [self.make_prediction(x, self.root) for x in X]\n",
    "\n",
    "        #it returns a new array where there is prediction for each input, for x in X\n",
    "\n",
    "        return preditions\n",
    "\n",
    "    def make_prediction(self, x, tree):\n",
    "        ''' function to predict a single data point '''\n",
    "\n",
    "        #it will pass your input array into the tree u created\n",
    "\n",
    "        if tree.value!=None: return tree.value\n",
    "        feature_val = x[tree.feature_index]\n",
    "        if feature_val<=tree.threshold:\n",
    "            return self.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6557874",
   "metadata": {
    "id": "a6557874"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  X = data.iloc[:, :-1].values:\\n\\ndata.iloc[:, :-1]: Selects all rows and all columns except the last one in the DataFrame data.\\n.values: Converts the selected DataFrame subset into a NumPy array.\\nX: Represents the feature matrix. It contains all the rows and all columns of data except the last column.  '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:, :-1].values\n",
    "Y = data.iloc[:, -1].values.reshape(-1,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=41)\n",
    "\n",
    "'''  X = data.iloc[:, :-1].values:\n",
    "\n",
    "data.iloc[:, :-1]: Selects all rows and all columns except the last one in the DataFrame data.\n",
    ".values: Converts the selected DataFrame subset into a NumPy array.\n",
    "X: Represents the feature matrix. It contains all the rows and all columns of data except the last column.  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba891910",
   "metadata": {
    "id": "ba891910",
    "outputId": "27a2a571-90e5-4d06-bae1-f2b2e24a19fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_2 <= 1.9 ? 0.33741385372714494\n",
      " left:Setosa\n",
      " right:X_3 <= 1.5 ? 0.427106638180289\n",
      "  left:X_2 <= 4.9 ? 0.05124653739612173\n",
      "    left:Versicolor\n",
      "    right:Virginica\n",
      "  right:X_2 <= 5.0 ? 0.019631171921475288\n",
      "    left:X_1 <= 2.8 ? 0.20833333333333334\n",
      "        left:Virginica\n",
      "        right:Versicolor\n",
      "    right:Virginica\n"
     ]
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier(min_samples_split=3, max_depth=3)\n",
    "classifier.fit(X_train,Y_train)\n",
    "classifier.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60fb4a22",
   "metadata": {
    "id": "60fb4a22",
    "outputId": "6c2e1caf-bcbd-486d-e839-314daa110cfb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "715211cc",
   "metadata": {
    "id": "715211cc",
    "outputId": "5f818162-6ef2-4802-9ba0-7dbb8a32cfca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Virginica', 'Virginica', 'Virginica', 'Versicolor', 'Virginica', 'Versicolor', 'Virginica', 'Versicolor', 'Virginica', 'Virginica', 'Versicolor', 'Setosa', 'Setosa', 'Versicolor', 'Setosa', 'Virginica', 'Setosa', 'Virginica', 'Setosa', 'Setosa', 'Versicolor', 'Virginica', 'Setosa', 'Setosa', 'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor', 'Setosa', 'Versicolor']\n"
     ]
    }
   ],
   "source": [
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a89cfb58",
   "metadata": {
    "id": "a89cfb58",
    "outputId": "5ab0cc6a-17df-4b12-a29f-f27d1d61cb50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Virginica']\n",
      " ['Virginica']\n",
      " ['Virginica']\n",
      " ['Versicolor']\n",
      " ['Virginica']\n",
      " ['Versicolor']\n",
      " ['Virginica']\n",
      " ['Versicolor']\n",
      " ['Virginica']\n",
      " ['Virginica']\n",
      " ['Virginica']\n",
      " ['Setosa']\n",
      " ['Setosa']\n",
      " ['Versicolor']\n",
      " ['Setosa']\n",
      " ['Virginica']\n",
      " ['Setosa']\n",
      " ['Versicolor']\n",
      " ['Setosa']\n",
      " ['Setosa']\n",
      " ['Versicolor']\n",
      " ['Virginica']\n",
      " ['Setosa']\n",
      " ['Setosa']\n",
      " ['Versicolor']\n",
      " ['Versicolor']\n",
      " ['Versicolor']\n",
      " ['Versicolor']\n",
      " ['Setosa']\n",
      " ['Versicolor']]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a49cec4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "executionInfo": {
     "elapsed": 417,
     "status": "error",
     "timestamp": 1709132491304,
     "user": {
      "displayName": "Cylia Khelifi",
      "userId": "15337881315503988180"
     },
     "user_tz": -60
    },
    "id": "0a49cec4",
    "outputId": "0b3c20b9-8254-4e79-c9ac-94ff7b958546"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Virginica', 'Setosa']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = [[5., 4.3, 5.5, 2.2],[3.6, 3.9, 1.7, 0.2]]\n",
    "hp = classifier.predict(h)\n",
    "hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fdb2ee-ab23-4e0d-97f3-4d3fb26360ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
